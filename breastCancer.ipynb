{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-01]Scikit_dataset_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#프로젝트를 진행하는 데 필요한 라이브러리"
      ],
      "metadata": {
        "id": "KvZOtHbTCpU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# 모델들의 평가지표를 확인 하기 위해 출력했을 때 경고메세지 발생\n",
        "# 평가지표를 확인하기에 불편하기 때문에 경고 메세지를 무시하기 위해 ignore 설정\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 데이터를 train data, test data로 분리하기 위한 함수\n",
        "\n",
        "# 5가지 모델 성능 비교를 위한 모델 호출\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
        "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
        "from sklearn import svm # SVM\n",
        "from sklearn.linear_model import SGDClassifier # SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression # LogisticRegression\n",
        "\n",
        "import pandas as pd # 데이터를 DataFrame 형태로 확인 하기 위함\n",
        "import matplotlib.pyplot as plt # 데이터의 형태를 시각화 하여 확인하기 위함\n",
        "\n",
        "# 제대로 잘 학습 되었는지 확인하기 위한 평가지표\n",
        "from sklearn.metrics import accuracy_score # 정확도\n",
        "from sklearn.metrics import classification_report # 평가지표(척도)"
      ],
      "metadata": {
        "id": "c8cBoVuKAhoE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 클래스 설계\n",
        "##### - train data, test data 분리\n",
        "##### - decision_tree, random_forest, svm, sgd_classifier, logistic_regression 5가지 모델 성능 비교를 위한 학습 진행 및 모델 평가지표 출력\n"
      ],
      "metadata": {
        "id": "itReMheiDBtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model: # 클래스 생성\n",
        "\n",
        "    def __init__(self, list_, data, label): # 초기화 함수\n",
        "        self.list_ = list_ # list_ 변수 초기화\n",
        "        self.data = data # data 변수 초기화\n",
        "        self.label = label # label 변수 초기화\n",
        "\n",
        "\n",
        "    def data_split(self): # 데이터 분리 함수 생성\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.data, self.label,\n",
        "                                                            test_size=0.2, random_state=7)\n",
        "        \n",
        "        # self.data를 Feature Data로 지정, self.label를 Label Data로 지정하고 \n",
        "        # test_data 크기를 전체 비율 중 20%(0.2)로 지정,\n",
        "        # 데이터를 섞고 random_state를 7로 지정함으로써 계속 고정된 데이터를 사용할 수 있음\n",
        "\n",
        "        # a = int(len(self.data)*0.8)\n",
        "        # b = int(len(self.label)*0.8)\n",
        "\n",
        "        # X_train = data[:a]\n",
        "        # X_test = data[a:]\n",
        "\n",
        "        # y_train = label[:b]\n",
        "        # y_test = label[b:]\n",
        "\n",
        "        # train_test_split() 함수를 써도 되지만 위와 같이 비율을 정해 직접 데이터를 나눌 수도 있음\n",
        "\n",
        "        return X_train, X_test, y_train, y_test # 모델 학습 및 평가를 위해 X_train, X_test, y_train, y_test 반환\n",
        "\n",
        "\n",
        "    def classifiler_model(self): # 5가지 분류 모델에 대한 학습 및 평가를 진행하기 위한 함수 생성\n",
        "\n",
        "        X_train, X_test, y_train, y_test = self.data_split() # 클래스 내의 data_split() 함수 호출하여 데이터 분리\n",
        "\n",
        "        for i in self.list_: # 각 리스트와 일치하는 모델에 대해 학습 진행하기 위해 입력받은 리스트를 for문에 삽입\n",
        "            if i == 'decision_tree': \n",
        "                a = DecisionTreeClassifier(random_state=6)\n",
        "                # 만약 i가 'decision_tree'라면 모델을 DecisionTreeClassifier(random_state=6)로 설정\n",
        "\n",
        "            elif i == 'random_forest':\n",
        "                a = RandomForestClassifier(random_state=32)\n",
        "                # 만약 i가 'random_forest'라면 모델을 RandomForestClassifier(random_state=32)로 설정\n",
        "\n",
        "            elif i == 'svm':\n",
        "                a = svm.SVC(random_state=44)\n",
        "                # 만약 i가 'svm'라면 모델을 svm.SVC(random_state=44)로 설정\n",
        "\n",
        "            elif i == 'sgd_classifier':\n",
        "                a = SGDClassifier(random_state=22)\n",
        "                # 만약 i가 'sgd_classifier'라면 모델을 SGDClassifier(random_state=22)로 설정\n",
        "\n",
        "            elif i == 'logistic_regression':\n",
        "                a = LogisticRegression(random_state=10)\n",
        "                # 만약 i가 'logistic_regression'라면 모델을 LogisticRegression(random_state=10)로 설정\n",
        "\n",
        "            model = a # i에 따라 지정된 모델을 model에 할당\n",
        "            model.fit(X_train, y_train) # 할당된 모델로 X(train)에 대한 y(train)학습 진행\n",
        "            y_pred = model.predict(X_test) # 학습한 것을 토대로 X(test)에 대해서 y(test)값 예측한 것을 y_pred에 할당\n",
        "            \n",
        "            print(i, \"의 평가지표\") # 어떤 모델에 대한 평가 지표인가를 출력\n",
        "            print(classification_report(y_test, y_pred)) # 실제 값과 예측값을 비교했을 때 모델의 성능이 어느 정도인가 평가지표 출력\n"
      ],
      "metadata": {
        "id": "UZbJQfkTBh8D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#리스트 생성\n",
        "#####모델에 따른 학습 진행 및 평가지표 출력을 위해 입력할 모델 리스트"
      ],
      "metadata": {
        "id": "AyDsWqYOD6Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "li_1 = ['decision_tree', 'random_forest', 'svm', 'sgd_classifier', 'logistic_regression']"
      ],
      "metadata": {
        "id": "lnHOm2h5Bqnq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Digits Project"
      ],
      "metadata": {
        "id": "3VkkmyxKD5oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Feature Data, Label Data 지정하기\n",
        "\n"
      ],
      "metadata": {
        "id": "KpPLGJWxXMqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "jiGUkzdzZsEV",
        "outputId": "860c67b0-f63b-473c-af00-8eca7aeb5d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
            "digits_data.shape:  (1797, 64)\n",
            "digits_data[0]:  [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
            " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
            "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
            "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digits_label.shape:  (1797,)\n",
            "digits_label[:20] [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
            "feature_names:  ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
            "target_names:  [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.datasets import load_digits # 손글씨 데이터셋 호출\n",
        "\n",
        "digits = load_digits() # digits 변수에 불러온 digits 데이터 할당\n",
        "print(digits.keys()) # digits 내의 데이터 확인\n",
        "\n",
        "digits_data = digits.data # feature data 지정\n",
        "print(\"digits_data.shape: \", digits_data.shape) # 데이터 파악: (1797, 64) 총 1797개의 데이터가 있고 데이터 하나당 64개의 데이터를 가지고 있음\n",
        "\n",
        "print(\"digits_data[0]: \", digits_data[0]) # 각 숫자: 픽셀 값 의미 (8*8)크기의 이미지의미\n",
        "\n",
        "# 10개의 data(feature) 이미지 출력해보기\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1) # 위치 지정\n",
        "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray') # 8*8 형태의 이미지 출력 데이터 크기 지정\n",
        "    plt.axis('off') # 축 제거\n",
        "plt.show() # 0~9까지의 데이터 확인 가능\n",
        "\n",
        "digits_label = digits.target # label data 지정\n",
        "print(\"digits_label.shape: \", digits_label.shape) # 총 1797개의 데이터가 있음\n",
        "print(\"digits_label[:20]\", digits_label[:20]) # 0~9까지 숫자로 나타냄, 이미지 데이터가 어떤 숫자를 나타내는지 담고 있음\n",
        "\n",
        "print(\"feature_names: \", digits.feature_names) # 픽셀 하나하나에 대한 이름 나타냄\n",
        "print(\"target_names: \", digits.target_names) # 0~9를 나타냄, [0 1 2 3 4 5 6 7 8 9]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####데이터 Describe 해 보기"
      ],
      "metadata": {
        "id": "sRmRXLbsXVOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.DESCR) # 데이터에 대한 요약 정보 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzZ88P2tYw3o",
        "outputId": "9d69c3ec-c21e-4dbc-ab82-a7965828b7e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####모델 성능 평가"
      ],
      "metadata": {
        "id": "aOUZ4PTWXbfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_digits = model(list_=li_1, data=digits_data, label=digits_label) # digits, 손글씨 데이터에 대해 다양한 모델을 학습시키기 위해 클래스 객체 생성\n",
        "model_digits.data_split() # 객체 내 데이터 분리 함수를 통해 train data, test data 분리\n",
        "model_digits.classifiler_model() # 객체 내 classifiler_model()함수를 통해 손글씨 데이터에 대한 다양한 모델의 학습을 진행하고 모델 성능 평가지표 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCBQMfT4Cd6F",
        "outputId": "46476b1b-febc-44cc-9789-2415d1381446"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_tree 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.84      0.90      0.87        42\n",
            "           2       0.87      0.85      0.86        40\n",
            "           3       0.79      0.91      0.85        34\n",
            "           4       0.80      0.95      0.86        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       1.00      0.93      0.96        28\n",
            "           7       0.93      0.82      0.87        33\n",
            "           8       0.88      0.65      0.75        43\n",
            "           9       0.76      0.81      0.79        32\n",
            "\n",
            "    accuracy                           0.87       360\n",
            "   macro avg       0.88      0.88      0.87       360\n",
            "weighted avg       0.88      0.87      0.87       360\n",
            "\n",
            "random_forest 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.93      1.00      0.97        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       0.93      1.00      0.96        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.94      0.97      0.96        33\n",
            "           8       1.00      0.84      0.91        43\n",
            "           9       0.94      0.94      0.94        32\n",
            "\n",
            "    accuracy                           0.96       360\n",
            "   macro avg       0.96      0.96      0.96       360\n",
            "weighted avg       0.97      0.96      0.96       360\n",
            "\n",
            "svm 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      1.00      0.98        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        37\n",
            "           5       0.93      1.00      0.97        28\n",
            "           6       1.00      1.00      1.00        28\n",
            "           7       1.00      1.00      1.00        33\n",
            "           8       1.00      0.93      0.96        43\n",
            "           9       1.00      0.97      0.98        32\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "sgd_classifier 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.82      0.86      0.84        42\n",
            "           2       0.95      1.00      0.98        40\n",
            "           3       0.91      0.88      0.90        34\n",
            "           4       0.74      1.00      0.85        37\n",
            "           5       0.85      1.00      0.92        28\n",
            "           6       1.00      0.93      0.96        28\n",
            "           7       0.91      0.88      0.89        33\n",
            "           8       1.00      0.58      0.74        43\n",
            "           9       0.91      0.94      0.92        32\n",
            "\n",
            "    accuracy                           0.90       360\n",
            "   macro avg       0.91      0.90      0.90       360\n",
            "weighted avg       0.91      0.90      0.89       360\n",
            "\n",
            "logistic_regression 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      0.95      0.95        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.94      0.97      0.96        34\n",
            "           4       0.97      1.00      0.99        37\n",
            "           5       0.82      0.96      0.89        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.92      0.81      0.86        43\n",
            "           9       0.97      0.91      0.94        32\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####결론"
      ],
      "metadata": {
        "id": "6iIGuYqlXgBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "손글씨를 분류할 때는 맞는 것을 틀렸다고 하는 것 보다 틀린 것을 맞다고 하지 않는 것이 더 중요하다. 이러한 경우 정밀도(Precision)가 중요한 분류 문제 이기 때문에 위의 모델 성능 평가 지표에서 정밀도가 가장 높게 나온 SVM이 현재 프로젝트에서 가장 좋은 분류 모델이다."
      ],
      "metadata": {
        "id": "rwT8Otxvbe3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wine Project"
      ],
      "metadata": {
        "id": "_wl-3POZEimT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Feature Data, Label Data 지정하기\n",
        "\n"
      ],
      "metadata": {
        "id": "_yzBeTBqgcLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_wine # 와인 데이터셋 호출\n",
        "\n",
        "wine = load_wine() # wine 변수에 불러온 wine 데이터 할당\n",
        "\n",
        "print(wine.keys()) # wine 내의 데이터 확인\n",
        "\n",
        "wine_data = wine.data # feature data 지정\n",
        "print(\"wine_data.shape: \", wine_data.shape) # 데이터 파악: (178, 13) 총 178개의 데이터가 있고 데이터 하나당 13개의 데이터를 가지고 있음\n",
        "print(\"wine_data[0]:\", wine_data[0]) # 13가지의 feature에 대한 값\n",
        "\n",
        "\n",
        "wine_label = wine.target # label data 지정\n",
        "print(\"wine_label.shape: \", wine_label.shape) # 총 178개의 데이터가 있음\n",
        "print(\"wine_label[:20]: \", wine_label[:20]) # 0, 1, 2로 표현 [:20]에는 0만 있음\n",
        "\n",
        "print(\"feature_names: \", wine.feature_names) # 각 feature에 대한 이름\n",
        "# ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', \n",
        "# 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] 등이 있음\n",
        "\n",
        "print(\"target_names: \", wine.target_names) # ['class_0' 'class_1' 'class_2']로 wine 종류를 분류해 냄\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeWpOCK8Bwkr",
        "outputId": "e061ed34-98e3-4dd6-fdba-c240494f6954"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
            "wine_data.shape:  (178, 13)\n",
            "wine_data[0]: [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "wine_label.shape:  (178,)\n",
            "wine_label[:20]:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "feature_names:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "target_names:  ['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####데이터 Describe 해 보기"
      ],
      "metadata": {
        "id": "zVdjnk5MhR6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wine.DESCR) # 데이터에 대한 요약 정보 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRm-FJYdhSf7",
        "outputId": "f952db3e-b62e-46cd-f0e4-f34754024912"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DataFrame으로 한 눈에 데이터 파악하기"
      ],
      "metadata": {
        "id": "L6N1jksHha_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names) # wine에 대한 데이터를 한 눈에 보기 쉽도록 데이터 프레임 형태로 변환\n",
        "wine_df[\"target\"] = wine_label # wine_df에 label(target) 데이터 추가\n",
        "print(wine_df) # 데이터 프레임 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFalKq_phbbN",
        "outputId": "bda29373-28f3-47a5-d24a-4abdf1157722"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
            "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
            "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
            "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
            "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
            "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
            "..       ...         ...   ...                ...        ...            ...   \n",
            "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
            "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
            "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
            "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
            "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
            "\n",
            "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
            "0          3.06                  0.28             2.29             5.64  1.04   \n",
            "1          2.76                  0.26             1.28             4.38  1.05   \n",
            "2          3.24                  0.30             2.81             5.68  1.03   \n",
            "3          3.49                  0.24             2.18             7.80  0.86   \n",
            "4          2.69                  0.39             1.82             4.32  1.04   \n",
            "..          ...                   ...              ...              ...   ...   \n",
            "173        0.61                  0.52             1.06             7.70  0.64   \n",
            "174        0.75                  0.43             1.41             7.30  0.70   \n",
            "175        0.69                  0.43             1.35            10.20  0.59   \n",
            "176        0.68                  0.53             1.46             9.30  0.60   \n",
            "177        0.76                  0.56             1.35             9.20  0.61   \n",
            "\n",
            "     od280/od315_of_diluted_wines  proline  target  \n",
            "0                            3.92   1065.0       0  \n",
            "1                            3.40   1050.0       0  \n",
            "2                            3.17   1185.0       0  \n",
            "3                            3.45   1480.0       0  \n",
            "4                            2.93    735.0       0  \n",
            "..                            ...      ...     ...  \n",
            "173                          1.74    740.0       2  \n",
            "174                          1.56    750.0       2  \n",
            "175                          1.56    835.0       2  \n",
            "176                          1.62    840.0       2  \n",
            "177                          1.60    560.0       2  \n",
            "\n",
            "[178 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####모델 성능 평가"
      ],
      "metadata": {
        "id": "zWT0r6cmh9MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = model(list_=li_1, data=wine_data, label=wine_label) # wine, 와인 데이터에 대해 다양한 모델을 학습시키기 위해 클래스 객체 생성\n",
        "model_digits.data_split() # 객체 내 데이터 분리 함수를 통해 train data, test data 분리\n",
        "model_1.classifiler_model() # 객체 내 classifiler_model()함수를 통해 와인 데이터에 대한 다양한 모델의 학습을 진행하고 모델 성능 평가지표 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NctBykf1CilE",
        "outputId": "1c6d15a4-8e15-4a4a-c7fc-d9e91c7750d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_tree 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.88         7\n",
            "           1       0.94      0.94      0.94        17\n",
            "           2       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.91      0.92      0.91        36\n",
            "weighted avg       0.93      0.92      0.92        36\n",
            "\n",
            "random_forest 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "svm 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.58      0.88      0.70        17\n",
            "           2       0.33      0.08      0.13        12\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.59      0.61      0.56        36\n",
            "weighted avg       0.55      0.61      0.54        36\n",
            "\n",
            "sgd_classifier 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70         7\n",
            "           1       0.00      0.00      0.00        17\n",
            "           2       0.35      0.67      0.46        12\n",
            "\n",
            "    accuracy                           0.42        36\n",
            "   macro avg       0.30      0.56      0.39        36\n",
            "weighted avg       0.22      0.42      0.29        36\n",
            "\n",
            "logistic_regression 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       0.94      1.00      0.97        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.95      0.96        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####결론"
      ],
      "metadata": {
        "id": "vHKxUDsYik6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "와인을 분류할 때는 맞는 것을 틀렸다고 하지 않는 것도 중요하고 틀린것도 맞다고 하지 않는 것 둘 다 중요하다. 1번 와인을 2번 와인으로 잘 못 분류하면 와인 종류 자체가 달라지기 때문에 이러한 경우 Recall, Precision 모두 중요한데 Recall과 Precision은 상충하는 개념이기 때문에 하나가 높아지면 다른 하나는 낮아진다.\n",
        "\n",
        "이러한 경우 Recall과 Precision의 균형값 F1 score를 이용해 모델을 평가하는 것이 좋다.\n",
        "\n",
        "위의 모델 성능 평가 지표를 봤을 때 F1 score가 가장 높게 나온 Random Forest가 가장 성능이 좋은 모델이나, 모든 평가도가 1.00 인 경우 오버피팅이 일어났을 수도 있기 때문에 다음으로 F1 score가 높은 Logistic Regression가 현재 프로젝트에서 가장 적절한 모델이다."
      ],
      "metadata": {
        "id": "wkAcinNBipSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Breast_cancer Project"
      ],
      "metadata": {
        "id": "n5bVGcxfE3OO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Feature Data, Label Data 지정하기\n",
        "\n"
      ],
      "metadata": {
        "id": "znBeFbZQleS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer # 유방암 데이터셋 호출\n",
        "\n",
        "breast_cancer = load_breast_cancer() # breast_cancer 변수에 불러온 breast_cancer 데이터 할당\n",
        "\n",
        "print(breast_cancer.keys()) # breast_cancer 내의 데이터 확인\n",
        "\n",
        "breast_cancer_data = breast_cancer.data # feature data 지정\n",
        "print(\"breast_cancer_data.shape: \", breast_cancer_data.shape) # 데이터 파악: (569, 30) 총 569개의 데이터가 있고 데이터 하나당 30개의 데이터를 가지고 있음\n",
        "print(\"breast_cancer_data[0]: \", breast_cancer_data[0]) # 30가지의 feature에 대한 값\n",
        "\n",
        "\n",
        "breast_cancer_label = breast_cancer.target # label data 지정\n",
        "print(\"breast_cancer_label.shape: \", breast_cancer_label.shape) # 총 569개의 데이터가 있음\n",
        "print(\"breast_cancer_label[:30]: \", breast_cancer_label[:30]) # 0또는 1로 나타냄\n",
        "#\n",
        "print(\"feature_names: \", breast_cancer.feature_names) # 각 feature에 대한 이름\n",
        "# ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
        "#  'mean smoothness' 'mean compactness' 'mean concavity'\n",
        "#  'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
        "#  'radius error' 'texture error' 'perimeter error' 'area error'\n",
        "#  'smoothness error' 'compactness error' 'concavity error'\n",
        "#  'concave points error' 'symmetry error' 'fractal dimension error'\n",
        "#  'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
        "#  'worst smoothness' 'worst compactness' 'worst concavity'\n",
        "#  'worst concave points' 'worst symmetry' 'worst fractal dimension'] 등이 있음\n",
        "\n",
        "print(\"target_names: \", breast_cancer.target_names) # ['malignant' 'benign']로 유방암 이다 아니다를 분류함\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRBWKaEJBzSI",
        "outputId": "2d38ee60-9ef8-4389-d356-558b4c6bda33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            "breast_cancer_data.shape:  (569, 30)\n",
            "breast_cancer_data[0]:  [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "breast_cancer_label.shape:  (569,)\n",
            "breast_cancer_label[:30]:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
            "feature_names:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "target_names:  ['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####데이터 Describe 해 보기"
      ],
      "metadata": {
        "id": "MtwDn5jhjoA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer.DESCR) # 데이터에 대한 요약 정보 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgZXa0iYjrc0",
        "outputId": "2d89a96c-312e-45d7-f308-7fcd78c1dce6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DataFrame으로 한 눈에 데이터 파악하기"
      ],
      "metadata": {
        "id": "mhVHCUvGjwCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df = pd.DataFrame(data=breast_cancer_data, columns=breast_cancer.feature_names)  # breast_cancer에 대한 데이터를 한 눈에 보기 쉽도록 데이터 프레임 형태로 변환\n",
        "breast_cancer_df[\"target\"] = breast_cancer_label #breast_cancer_df에 label(target) 데이터 추가\n",
        "print(breast_cancer_df) # 데이터 프레임 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgxxHYlgjw9f",
        "outputId": "95b7896e-352f-4dab-8bab-08c15c6ed8c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0          17.99         10.38          122.80     1001.0          0.11840   \n",
            "1          20.57         17.77          132.90     1326.0          0.08474   \n",
            "2          19.69         21.25          130.00     1203.0          0.10960   \n",
            "3          11.42         20.38           77.58      386.1          0.14250   \n",
            "4          20.29         14.34          135.10     1297.0          0.10030   \n",
            "..           ...           ...             ...        ...              ...   \n",
            "564        21.56         22.39          142.00     1479.0          0.11100   \n",
            "565        20.13         28.25          131.20     1261.0          0.09780   \n",
            "566        16.60         28.08          108.30      858.1          0.08455   \n",
            "567        20.60         29.33          140.10     1265.0          0.11780   \n",
            "568         7.76         24.54           47.92      181.0          0.05263   \n",
            "\n",
            "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0             0.27760         0.30010              0.14710         0.2419   \n",
            "1             0.07864         0.08690              0.07017         0.1812   \n",
            "2             0.15990         0.19740              0.12790         0.2069   \n",
            "3             0.28390         0.24140              0.10520         0.2597   \n",
            "4             0.13280         0.19800              0.10430         0.1809   \n",
            "..                ...             ...                  ...            ...   \n",
            "564           0.11590         0.24390              0.13890         0.1726   \n",
            "565           0.10340         0.14400              0.09791         0.1752   \n",
            "566           0.10230         0.09251              0.05302         0.1590   \n",
            "567           0.27700         0.35140              0.15200         0.2397   \n",
            "568           0.04362         0.00000              0.00000         0.1587   \n",
            "\n",
            "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
            "0                   0.07871  ...          17.33           184.60      2019.0   \n",
            "1                   0.05667  ...          23.41           158.80      1956.0   \n",
            "2                   0.05999  ...          25.53           152.50      1709.0   \n",
            "3                   0.09744  ...          26.50            98.87       567.7   \n",
            "4                   0.05883  ...          16.67           152.20      1575.0   \n",
            "..                      ...  ...            ...              ...         ...   \n",
            "564                 0.05623  ...          26.40           166.10      2027.0   \n",
            "565                 0.05533  ...          38.25           155.00      1731.0   \n",
            "566                 0.05648  ...          34.12           126.70      1124.0   \n",
            "567                 0.07016  ...          39.42           184.60      1821.0   \n",
            "568                 0.05884  ...          30.37            59.16       268.6   \n",
            "\n",
            "     worst smoothness  worst compactness  worst concavity  \\\n",
            "0             0.16220            0.66560           0.7119   \n",
            "1             0.12380            0.18660           0.2416   \n",
            "2             0.14440            0.42450           0.4504   \n",
            "3             0.20980            0.86630           0.6869   \n",
            "4             0.13740            0.20500           0.4000   \n",
            "..                ...                ...              ...   \n",
            "564           0.14100            0.21130           0.4107   \n",
            "565           0.11660            0.19220           0.3215   \n",
            "566           0.11390            0.30940           0.3403   \n",
            "567           0.16500            0.86810           0.9387   \n",
            "568           0.08996            0.06444           0.0000   \n",
            "\n",
            "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
            "0                  0.2654          0.4601                  0.11890       0  \n",
            "1                  0.1860          0.2750                  0.08902       0  \n",
            "2                  0.2430          0.3613                  0.08758       0  \n",
            "3                  0.2575          0.6638                  0.17300       0  \n",
            "4                  0.1625          0.2364                  0.07678       0  \n",
            "..                    ...             ...                      ...     ...  \n",
            "564                0.2216          0.2060                  0.07115       0  \n",
            "565                0.1628          0.2572                  0.06637       0  \n",
            "566                0.1418          0.2218                  0.07820       0  \n",
            "567                0.2650          0.4087                  0.12400       0  \n",
            "568                0.0000          0.2871                  0.07039       1  \n",
            "\n",
            "[569 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####모델 성능 평가"
      ],
      "metadata": {
        "id": "GXS_jzTujgdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = model(list_=li_1, data=breast_cancer_data, label=breast_cancer_label) # breast_cancer, 유방암 데이터에 대해 다양한 모델을 학습시키기 위해 클래스 객체 생성\n",
        "model_1.data_split() # 객체 내 데이터 분리 함수를 통해 train data, test data 분리\n",
        "model_1.classifiler_model() # 객체 내 classifiler_model()함수를 통해 유방암 데이터에 대한 다양한 모델의 학습을 진행하고 모델 성능 평가지표 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHV3PIhpCmmK",
        "outputId": "efbe7450-b60e-46a4-8302-f94fd0f8c6da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_tree 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87        40\n",
            "           1       0.91      0.96      0.93        74\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.89      0.90       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n",
            "random_forest 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       114\n",
            "   macro avg       1.00      1.00      1.00       114\n",
            "weighted avg       1.00      1.00      1.00       114\n",
            "\n",
            "svm 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.72      0.84        40\n",
            "           1       0.87      1.00      0.93        74\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.94      0.86      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "sgd_classifier 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.47      0.64        40\n",
            "           1       0.78      1.00      0.88        74\n",
            "\n",
            "    accuracy                           0.82       114\n",
            "   macro avg       0.89      0.74      0.76       114\n",
            "weighted avg       0.86      0.82      0.79       114\n",
            "\n",
            "logistic_regression 의 평가지표\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        40\n",
            "           1       0.91      1.00      0.95        74\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####결론"
      ],
      "metadata": {
        "id": "Upq1X_IElnpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유방암을 분류할 때는 유방암인 것을 유방암이 아니다라고 하지 않는 것이 매우 중요하다. 유방암이 아닌데 유방암이라고 하는 경우는 단순한 헤프닝이지만 유방암인데 유방암이 아니라고 하는 경우는 매우 위험한 상황이기 때문에 이러한 상황에서는 ReCall(재현율)이 중요하다.\n",
        "\n",
        "위의 모델 성능 평가 지표를 봤을 때 ReCall이 가장 높게 나온 Random Forest가 가장 성능이 좋은 모델이나, 모든 평가도가 1.00 인 경우 오버피팅이 일어났을 수도 있기 때문에 다음으로 ReCall이 높은 Logistic Regression가 현재 프로젝트에서 가장 적절한 모델이다."
      ],
      "metadata": {
        "id": "-B6irvaynevl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#회고"
      ],
      "metadata": {
        "id": "iuKUAoHXFDnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "평소 머신러닝, 딥러닝 프로젝트를 진행하면서 모델의 성능을 평가할 때 정확도가 아닌 평가 기준을 사용한 경험은 없었는데 이번 프로젝트를 진행하는 과정을 통해 sklearn.metrics의 classification_report를 사용하는 방식으로 정확도 외에 다양한 평가 기준을 사용해 보면서 깊게 익힐 수 있었다.\n",
        "\n",
        "개념만 보았을 때는 이해는 되었지만 응용을 잘 할 자신은 없었는데 프로젝트를 통해 직접 부딪혀보고 사용해 봄으로써 앞으로도 다양하게 활용해 볼 수 있도록 익힐 수 있는 기회가 되었다.\n",
        "\n",
        "일부 프로젝트에서 Random Forest와 관련된 평가척도가 모두 1.00으로 나와 개인적인 견해로 오버피팅이 되었을 것이다! 라고 생각되는 모호한 부분이 있지만 앞으로 학습하면서 이와 관련된 부분을 이해하고 해결해 나갈 것이다."
      ],
      "metadata": {
        "id": "FZvN_0pbltIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 참고"
      ],
      "metadata": {
        "id": "K49SBq4Pc-cB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://hleecaster.com/ml-accuracy-recall-precision-f1/"
      ],
      "metadata": {
        "id": "2GNBY1FLdA52"
      }
    }
  ]
}
